[net]
# Training
batch=4
subdivisions=4
width=512
height=512
channels=3
learning_rate=1e-7
momentum=0.9
decay=0.0005
adam=0
B1=0.9
B2=0.999
eps=0.0000001
max_batches = 40000

##########################conv1
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=tanh

# Downsample

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=tanh

[shortcut]
from=-3
activation=linear

######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=tanh

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=tanh

[upsample]
stride=2

[route]
layers = -1, 37

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=tanh

[convolutional]
size=1
stride=1
pad=1
filters=256
activation=linear

[upsample]
stride=2

[route]
layers = -1, 24

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=128
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=256
activation=tanh

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=tanh

[convolutional]
size=1
stride=1
pad=1
filters=128
activation=linear

[upsample]
stride=2

[route]
layers = -1, 11

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=64
activation=tanh

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=64
activation=tanh

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=128
activation=tanh

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=tanh

[upsample]
stride=2

[route]
layers = -1, 4

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=32
activation=tanh

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=tanh

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=32
activation=tanh

[upsample]
stride=2

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=64
activation=tanh

[convolutional]
batch_normalize=1
filters=1
size=1
stride=1
activation=linear
################################

[logistic]